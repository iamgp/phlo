name: Publish to PyPI

on:
  release:
    types: [published]
  workflow_dispatch:
    inputs:
      dry_run:
        description: "Build packages but skip publishing to PyPI"
        required: false
        default: "false"
      base_ref:
        description: "Git ref to compare against for change detection (defaults to previous tag)"
        required: false
        default: ""

permissions:
  contents: read # Required to checkout private repo
  id-token: write # Required for trusted publishing

jobs:
  plan:
    runs-on: ubuntu-latest
    outputs:
      packages: ${{ steps.plan.outputs.packages }}
      has_packages: ${{ steps.plan.outputs.has_packages }}
      dry_run: ${{ steps.plan.outputs.dry_run }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Determine packages to publish
        id: plan
        env:
          BASE_REF: ${{ github.event_name == 'workflow_dispatch' && inputs.base_ref || '' }}
          DRY_RUN: ${{ github.event_name == 'workflow_dispatch' && inputs.dry_run || 'false' }}
        run: |
          python - <<'PY'
          from __future__ import annotations

          import json
          import os
          import re
          import subprocess
          from collections import deque
          from pathlib import Path
          import tomllib

          def run(args: list[str]) -> str:
              return subprocess.check_output(args, text=True).strip()

          def try_run(args: list[str]) -> str:
              try:
                  return run(args)
              except subprocess.CalledProcessError:
                  return ""

          def normalize_dep(dep: str) -> str:
              dep = dep.split(";", 1)[0].strip()
              if not dep:
                  return ""
              dep = dep.split("[", 1)[0]
              name = re.split(r"[<>=!~ ]", dep, 1)[0]
              return name.strip()

          root = Path(".")
          package_paths: dict[str, Path] = {}
          package_meta: dict[str, dict] = {}

          root_pyproject = root / "pyproject.toml"
          root_data = tomllib.loads(root_pyproject.read_text(encoding="utf-8"))
          root_name = root_data["project"]["name"]
          package_paths[root_name] = root
          package_meta[root_name] = root_data

          packages_dir = root / "packages"
          if packages_dir.exists():
              for pkg_dir in packages_dir.iterdir():
                  if not pkg_dir.is_dir():
                      continue
                  pyproject = pkg_dir / "pyproject.toml"
                  if not pyproject.exists():
                      continue
                  data = tomllib.loads(pyproject.read_text(encoding="utf-8"))
                  name = data["project"]["name"]
                  package_paths[name] = pkg_dir
                  package_meta[name] = data

          internal = set(package_paths)

          def deps_for(name: str) -> list[str]:
              data = package_meta[name]
              deps = list(data.get("project", {}).get("dependencies", []) or [])
              optional = data.get("project", {}).get("optional-dependencies", {}) or {}
              for group in optional.values():
                  deps.extend(group)
              internal_deps = []
              for dep in deps:
                  dep_name = normalize_dep(dep)
                  if dep_name in internal:
                      internal_deps.append(dep_name)
              return sorted(set(internal_deps))

          dep_map = {name: deps_for(name) for name in internal}

          event = os.environ.get("GITHUB_EVENT_NAME", "")
          base_ref = os.environ.get("BASE_REF", "").strip()
          current_tag = os.environ.get("GITHUB_REF_NAME", "") if event == "release" else ""

          if not base_ref:
              if current_tag:
                  base_ref = try_run(["git", "describe", "--tags", "--abbrev=0", f"{current_tag}^"])
              else:
                  base_ref = try_run(["git", "describe", "--tags", "--abbrev=0"])

          if base_ref:
              diff = try_run(["git", "diff", "--name-only", f"{base_ref}..HEAD"])
              changed_files = diff.splitlines() if diff else []
          else:
              changed_files = try_run(["git", "ls-files"]).splitlines()

          package_dir_to_name = {
              path.name: name for name, path in package_paths.items() if path != root
          }

          changed_packages: set[str] = set()
          for file in changed_files:
              if file.startswith("packages/"):
                  parts = file.split("/", 2)
                  if len(parts) > 1:
                      name = package_dir_to_name.get(parts[1])
                      if name:
                          changed_packages.add(name)
                  continue
              if (
                  file == "pyproject.toml"
                  or file.startswith("src/phlo/")
                  or file.startswith("registry/")
                  or file in {"README.md", "CHANGELOG.md"}
              ):
                  changed_packages.add(root_name)

          selected = set(changed_packages)
          in_deg = {name: 0 for name in selected}
          dependents: dict[str, list[str]] = {name: [] for name in selected}
          for name in selected:
              for dep in dep_map.get(name, []):
                  if dep in selected:
                      in_deg[name] += 1
                      dependents.setdefault(dep, []).append(name)

          queue = deque(sorted([name for name, deg in in_deg.items() if deg == 0]))
          order: list[str] = []
          while queue:
              node = queue.popleft()
              order.append(node)
              for dep in sorted(dependents.get(node, [])):
                  in_deg[dep] -= 1
                  if in_deg[dep] == 0:
                      queue.append(dep)

          remaining = sorted([name for name in selected if name not in order])
          order.extend(remaining)

          dry_run = os.environ.get("DRY_RUN", "false").strip().lower() == "true"
          outputs = {
              "packages": json.dumps(order),
              "has_packages": "true" if order else "false",
              "dry_run": "true" if dry_run else "false",
          }
          output_path = os.environ["GITHUB_OUTPUT"]
          with open(output_path, "a", encoding="utf-8") as fh:
              for key, value in outputs.items():
                  fh.write(f"{key}={value}\n")

          print(f"Base ref: {base_ref or '(none)'}")
          print(f"Changed files: {len(changed_files)}")
          print(f"Packages: {order}")
          PY

      - name: Log publish plan
        run: |
          echo "Dry run: ${{ steps.plan.outputs.dry_run }}"
          echo "Packages: ${{ steps.plan.outputs.packages }}"

  build:
    needs: plan
    if: needs.plan.outputs.has_packages == 'true'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install uv
        uses: astral-sh/setup-uv@v7
        with:
          version: "latest"

      - name: Set up Python
        run: uv python install 3.11

      - name: Build packages
        run: |
          rm -rf dist
          mkdir -p dist
          echo '${{ needs.plan.outputs.packages }}' > /tmp/packages.json
          python - <<'PY'
          import json
          import pathlib
          import subprocess

          packages = json.loads(pathlib.Path("/tmp/packages.json").read_text(encoding="utf-8"))
          if not packages:
              raise SystemExit("No packages selected for build.")
          for package in packages:
              subprocess.check_call(["uv", "build", "--package", package, "--out-dir", "dist"])
          PY

      - name: Upload artifacts
        uses: actions/upload-artifact@v6
        with:
          name: dist
          path: dist/

  publish:
    needs: [plan, build]
    if: needs.plan.outputs.has_packages == 'true' && needs.plan.outputs.dry_run != 'true'
    runs-on: ubuntu-latest
    environment: pypi # Configure this in GitHub repo settings
    steps:
      - name: Download artifacts
        uses: actions/download-artifact@v7
        with:
          name: dist
          path: dist/

      - name: Publish to PyPI
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          packages-dir: dist
        # Uses trusted publishing - configure at pypi.org/manage/project/phlo/settings/publishing/
