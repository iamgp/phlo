"""
Compose Generator Module

Generates docker-compose.yml and .env files from service definitions.
"""

import logging
import os
import shutil
from pathlib import Path
from typing import Any

import yaml

from phlo.discovery import ServiceDefinition, ServiceDiscovery

logger = logging.getLogger(__name__)


class ComposeGenerator:
    """Generates docker-compose.yml from service definitions."""

    def __init__(self, discovery: ServiceDiscovery):
        """Initialize with a service discovery instance."""
        self.discovery = discovery

    def generate_compose(
        self,
        services: list[ServiceDefinition],
        output_dir: Path,
        dev_mode: bool = False,
        phlo_src_path: str | None = None,
        user_overrides: dict[str, Any] | None = None,
    ) -> str:
        """Generate docker-compose.yml content.

        Args:
            services: List of services to include.
            output_dir: Target directory (for resolving relative paths).
            dev_mode: If True, add phlo source mounts for dev services.
            phlo_src_path: Path to phlo source (relative to project root).
            user_overrides: Dict of service name to ServiceOverride config from phlo.yaml.

        Returns:
            Docker compose YAML content as string.
        """
        # Sort services by dependencies
        sorted_services = self.discovery.resolve_dependencies(services)
        user_overrides = user_overrides or {}

        compose: dict[str, Any] = {"services": {}}

        for service in sorted_services:
            # Get user override for this service (if any)
            service_override = user_overrides.get(service.name, {})

            compose["services"][service.name] = self._build_service_config(
                service,
                output_dir,
                dev_mode=dev_mode,
                phlo_src_path=phlo_src_path,
                user_override=service_override,
            )

        # Add header comment with dev mode flag for stale detection
        dev_mode_str = "true" if dev_mode else "false"
        header = f"""# Phlo Infrastructure Stack
# Generated by: phlo services init
# Dev mode: {dev_mode_str}
# Modify .env to customize configuration

"""
        return header + yaml.dump(compose, default_flow_style=False, sort_keys=False)

    def _build_service_config(
        self,
        service: ServiceDefinition,
        output_dir: Path,
        dev_mode: bool = False,
        phlo_src_path: str | None = None,
        user_override: dict[str, Any] | None = None,
    ) -> dict[str, Any]:
        """Build docker-compose service configuration.

        Args:
            service: Service definition from package/core.
            output_dir: Output directory for relative paths.
            dev_mode: Whether to apply dev mode overrides.
            phlo_src_path: Path to phlo source.
            user_override: User overrides from phlo.yaml services section.
        """
        config: dict[str, Any] = {}
        user_override = user_override or {}

        # Image or build
        if service.image:
            config["image"] = service.image
        elif service.build:
            # Determine build context
            context = service.build.get("context", ".")
            if context == "source" and service.source_path:
                # Use the service's source directory as build context
                context = str(service.source_path)
            if isinstance(context, str):
                context_path = Path(context)
                if context_path.is_absolute():
                    context = os.path.relpath(context_path, output_dir)
            build_config: dict[str, Any] = {"context": context}
            if service.build.get("dockerfile"):
                build_config["dockerfile"] = service.build["dockerfile"]
            if service.build.get("args"):
                build_config["args"] = service.build["args"]
            config["build"] = build_config

        # Profile (if not default)
        if service.profile:
            config["profiles"] = [service.profile]

        # Compose configuration
        compose = service.compose

        if compose.get("restart"):
            config["restart"] = compose["restart"]
        else:
            config["restart"] = "unless-stopped"

        if compose.get("container_name"):
            config["container_name"] = compose["container_name"]

        if compose.get("environment"):
            config["environment"] = compose["environment"]

        if compose.get("ports"):
            config["ports"] = compose["ports"]

        if compose.get("volumes"):
            config["volumes"] = list(compose["volumes"])  # Copy to avoid mutation
        else:
            config["volumes"] = []

        # Dev mode: inject phlo source mount and project directory for dependency sync
        if dev_mode and service.phlo_dev and phlo_src_path:
            # Mount the phlo monorepo root for editable installs inside the container.
            # `phlo_src_path` points at `.../src/phlo`, so `../..` is the repo root.
            project_mount = f"{phlo_src_path}/../..:/opt/phlo-dev:rw"
            config["volumes"].append(project_mount)
            # Add environment variable to enable dev mode sync
            if "environment" not in config:
                config["environment"] = {}
            if isinstance(config["environment"], dict):
                config["environment"]["PHLO_DEV_MODE"] = "true"
            elif isinstance(config["environment"], list):
                config["environment"].append("PHLO_DEV_MODE=true")

        # Remove empty volumes list
        if not config["volumes"]:
            del config["volumes"]

        if dev_mode and service.dev:
            self._apply_dev_overrides(config, service, output_dir)

        # Add env_file for phlo_dev services to pick up project secrets (e.g., GITHUB_TOKEN)
        # Path is relative to .phlo/ directory where docker-compose.yml lives
        if service.phlo_dev:
            config["env_file"] = ["../.env"]

        if compose.get("command"):
            config["command"] = compose["command"]

        if compose.get("entrypoint"):
            config["entrypoint"] = compose["entrypoint"]

        if compose.get("healthcheck"):
            config["healthcheck"] = compose["healthcheck"]

        # Dependencies
        if service.depends_on:
            depends_config: dict[str, dict[str, str]] = {}
            for dep in service.depends_on:
                dep_service = self.discovery.get_service(dep)
                if dep_service:
                    # Check if dependency has healthcheck
                    if dep_service.compose.get("healthcheck"):
                        depends_config[dep] = {"condition": "service_healthy"}
                    elif dep == "minio-setup":
                        depends_config[dep] = {"condition": "service_completed_successfully"}
                    else:
                        depends_config[dep] = {"condition": "service_started"}
            if depends_config:
                config["depends_on"] = depends_config

        # Apply user overrides from phlo.yaml (last, so they take precedence)
        self._apply_user_overrides(config, user_override)

        return config

    def _apply_user_overrides(
        self,
        config: dict[str, Any],
        user_override: dict[str, Any],
    ) -> None:
        """Apply user overrides from phlo.yaml services section.

        Override behavior:
        - ports: replaces package default
        - environment: merges (user values override package)
        - volumes: appends to package defaults
        - depends_on: replaces package default
        - command: replaces package default
        """
        if not user_override:
            return

        # Ports: replace
        if user_override.get("ports"):
            config["ports"] = user_override["ports"]

        # Environment: merge (user takes precedence)
        if user_override.get("environment"):
            config.setdefault("environment", {})
            if isinstance(config["environment"], dict):
                config["environment"].update(user_override["environment"])
            elif isinstance(config["environment"], list):
                # Convert list format to dict then merge
                env_dict = {}
                for item in config["environment"]:
                    if "=" in item:
                        k, v = item.split("=", 1)
                        env_dict[k] = v
                env_dict.update(user_override["environment"])
                config["environment"] = env_dict

        # Volumes: append
        if user_override.get("volumes"):
            config.setdefault("volumes", [])
            config["volumes"].extend(user_override["volumes"])

        # Depends on: replace
        if user_override.get("depends_on"):
            depends_config = {}
            for dep in user_override["depends_on"]:
                depends_config[dep] = {"condition": "service_started"}
            config["depends_on"] = depends_config

        # Command: replace
        if user_override.get("command"):
            config["command"] = user_override["command"]

        # Healthcheck: replace (for inline services)
        if user_override.get("healthcheck"):
            config["healthcheck"] = user_override["healthcheck"]

    def _apply_dev_overrides(
        self,
        config: dict[str, Any],
        service: ServiceDefinition,
        output_dir: Path,
    ) -> None:
        dev = service.dev

        # Dev build: replace image with build context
        if dev.get("build"):
            # Remove image if present (we're building from source now)
            if "image" in config:
                del config["image"]

            build_ctx = dev["build"].get("context", ".")
            # Resolve {source} placeholder
            if "{source}" in build_ctx and service.source_path:
                build_ctx = os.path.relpath(service.source_path, output_dir)

            config["build"] = {
                "context": build_ctx,
                "dockerfile": dev["build"].get("dockerfile", "Dockerfile"),
            }

        if dev.get("environment"):
            config.setdefault("environment", {})
            if isinstance(config["environment"], dict):
                config["environment"].update(dev["environment"])
        if dev.get("command"):
            config["command"] = dev["command"]
        if dev.get("entrypoint"):
            config["entrypoint"] = dev["entrypoint"]
        if dev.get("ports"):
            config["ports"] = dev["ports"]
        if dev.get("volumes"):
            config["volumes"] = [
                self._resolve_dev_volume(volume, service, output_dir) for volume in dev["volumes"]
            ]

    def _resolve_dev_volume(
        self,
        volume: str,
        service: ServiceDefinition,
        output_dir: Path,
    ) -> str:
        if "{source}" not in volume or not service.source_path:
            return volume
        source_path = os.path.relpath(service.source_path, output_dir)
        return volume.replace("{source}", source_path)

    def generate_env(self, services: list[ServiceDefinition]) -> str:
        """Generate .env file content.

        Args:
            services: List of services to include.

        Returns:
            Environment file content as string.
        """
        lines = [
            "# Phlo Infrastructure Configuration",
            "# Generated by: phlo services init",
            "",
        ]

        # Group env vars by category
        categories: dict[str, list[tuple[str, dict[str, Any]]]] = {}

        for service in services:
            category = service.category
            if category not in categories:
                categories[category] = []

            for var_name, var_config in service.env_vars.items():
                categories[category].append((var_name, var_config))

        # Write grouped env vars
        category_titles = {
            "core": "Core Infrastructure",
            "orchestration": "Orchestration",
            "bi": "Business Intelligence",
            "admin": "Admin Tools",
            "api": "API Layer",
            "observability": "Observability",
        }

        for category, vars_list in categories.items():
            if not vars_list:
                continue

            title = category_titles.get(category, category.title())
            lines.append(f"# {title}")

            for var_name, var_config in vars_list:
                default = var_config.get("default", "")
                description = var_config.get("description", "")

                if description:
                    lines.append(f"# {description}")

                lines.append(f"{var_name}={default}")

            lines.append("")

        return "\n".join(lines)

    def copy_service_files(
        self,
        services: list[ServiceDefinition],
        output_dir: Path,
    ) -> list[str]:
        """Copy additional files required by services.

        Args:
            services: List of services.
            output_dir: Target .phlo directory.

        Returns:
            List of copied file paths.
        """
        copied: list[str] = []

        for service in services:
            if not service.files or not service.source_path:
                continue

            for file_spec in service.files:
                source = service.source_path / file_spec["source"]
                dest = output_dir / file_spec["dest"]

                if not source.exists():
                    logger.warning("Source file not found: %s", source)
                    continue

                # Create parent directories
                dest.parent.mkdir(parents=True, exist_ok=True)

                # Copy file or directory
                if source.is_dir():
                    if dest.exists():
                        shutil.rmtree(dest)
                    shutil.copytree(source, dest)
                else:
                    shutil.copy2(source, dest)

                copied.append(str(dest.relative_to(output_dir)))

        return copied

    def generate_gitignore(self) -> str:
        """Generate .gitignore content for .phlo directory."""
        return """# Phlo infrastructure files
.env
volumes/

# Dagster runtime data
dagster/storage/
dagster/history/
dagster/schedules/
dagster/logs/
"""
